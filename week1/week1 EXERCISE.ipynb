{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "datafolder = Path('C:\\\\Projects\\\\llm_engg\\\\llm_engineering\\\\Pdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "system_prompt = \"You are an assistant that analyzes the code. Respond in markdown.\\\n",
    "Include details if you have the information.\"\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def chatGptResponse(sys_prompt,qt):\n",
    "    message = \"Hello, GPT! This is my first ever message to you! Hi!\"\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"user\", \"content\": qt}\n",
    "              ],\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e63445fc-d59f-42ed-80af-ddd5966b0858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def chatGptResponseFile(filePath):\n",
    "    with open(filePath, 'r') as file:\n",
    "        file_content = file.read()\n",
    "    \n",
    "    # Make the API call\n",
    "        stream = openai.chat.completions.create(\n",
    "            model=MODEL_GPT,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond in markdown.\"},\n",
    "                {\"role\": \"user\", \"content\": file_content},\n",
    "                {\"role\": \"user\", \"content\": \"Can you understand this file data. GIve summary\"}\n",
    "            ],\n",
    "            stream=True\n",
    "        )\n",
    "        \n",
    "        response = \"\"\n",
    "        display_handle = display(Markdown(\"\"), display_id=True)\n",
    "        for chunk in stream:\n",
    "            response += chunk.choices[0].delta.content or ''\n",
    "            response = response.replace(\"```\",\"\").replace(\"markdown\", \"\")\n",
    "            update_display(Markdown(response), display_id=display_handle.display_id)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06d72abc-7c07-4b35-afcd-d884fa6049c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided Python script defines a class `SysToAsm` that is responsible for converting system definitions from a specified input file (in `.mdl` format) into assembly files. Here is a summary of the main components and functionalities of the code:\n",
       "\n",
       "### Overview\n",
       "- **Class Definition**: The `SysToAsm` class encapsulates functionality for converting system definitions to assembly files.\n",
       "- **Libraries Used**:\n",
       "  - `re`: For regular expression operations.\n",
       "  - `os`: For interacting with the operating system (file system operations).\n",
       "  - `Path` from `pathlib`: For handling file paths.\n",
       "  - Custom modules: \n",
       "    - `ParseModelSystem`: Contains classes and methods for parsing system definitions.\n",
       "    - `AssemblyFileCreation`: Deals with creation and management of assembly files.\n",
       "    - `utility_fncs`: Includes utility functions for various operations.\n",
       "\n",
       "### Key Methods\n",
       "1. **`__init__`**: Initializes instances of utility, assembly, and model system helper classes.\n",
       "2. **`nu_convert_system_to_assemblies`**: \n",
       "   - Converts a single system definition to assembly files.\n",
       "   - Extracts system definitions and system arguments, prepares assembly file content, applies regular expressions to handle system matches, and writes the output files to a specified directory.\n",
       "3. **`execute_sys_2_asm`**: \n",
       "   - Main method that processes the input file containing system definitions.\n",
       "   - Reads the file, extracts necessary system information, and calls `nu_convert_system_to_assemblies` for each system definition in the file.\n",
       "   - Updates the content of the original file with references to the newly created assembly files.\n",
       "\n",
       "### Functionality\n",
       "- **File Handling**: The code ensures specific directories for definitions and data are created if they do not exist.\n",
       "- **System Extraction**:\n",
       "  - The script uses regex patterns to identify specific system definitions.\n",
       "  - Extracts various blocks of information such as datasets, templates, graphics, and forms.\n",
       "- **Appending Additional Data**: Allows for additional datasets and definitions to be appended to system definitions.\n",
       "- **File Writing**: Writes the converted assembly files and logs completion.\n",
       "\n",
       "### Notes\n",
       "- The code indicates a focus on system designs, likely for engineering applications, where modeling and assembly of components are relevant.\n",
       "- Some inline comments suggest potential areas for expansion or modifications (e.g., handling additional definitions).\n",
       "\n",
       "### Conclusion\n",
       "The `SysToAsm` class offers a structured approach to convert model definitions into assembly files, making it a potentially useful tool for users working with system modeling software who need to export or restructure their models into assembly formats. The script is designed to facilitate automation in the conversion process, streamlining work for engineers or developers involved in system design and analysis."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatGptResponseFile((datafolder/'sys_to_assbly.py'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Llama 3.2 to answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
