{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006b2ea-9dfe-49c7-88a9-a5a0775185fd",
   "metadata": {},
   "source": [
    "# Additional End of week Exercise - week 2\n",
    "\n",
    "Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.\n",
    "\n",
    "This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!\n",
    "\n",
    "If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.\n",
    "\n",
    "I will publish a full solution here soon - unless someone beats me to it...\n",
    "\n",
    "There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!) I can't wait to see your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07e7793-b8f5-44f4-aded-5562f633271a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65295ed2-1a80-4d40-ad74-fef4719f0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai\n",
    "import anthropic\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d32509-6ff0-424c-a97d-d8fc82f506ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0451f456-556e-443b-b649-5885c963847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e621b048-5a1d-4843-b184-8dcf96cf17ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "datafolder = Path('C:\\\\Projects\\\\llm_engg\\\\llm_engineering\\\\Pdata')\n",
    "# constants\n",
    "\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea45a5e2-e7f9-4e82-8ab2-bfc1e977087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize conversation history\n",
    "conversation_history = [{\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond in markdown.\"}]\n",
    "\n",
    "# here is the question; type over this to ask something new\n",
    "system_prompt = \"You are an assistant that analyzes the code. Respond in markdown.\\\n",
    "Include details if you have the information.\"\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\"\n",
    "def getFileContent(fp):\n",
    "    \n",
    "    with open(fp, 'r') as file:\n",
    "        file_content = file.read()\n",
    "        return file_content\n",
    "    return \"\"\n",
    "    \n",
    "# Get gpt-4o-mini to answer, with streaming\n",
    "def chatGptResponse(qt,file):\n",
    "    \n",
    "    conversation_history.append({\"role\": \"user\", \"content\": qt})\n",
    "    if file: conversation_history.append({\"role\": \"user\", \"content\": getFileContent(file)})\n",
    "    stream = openai.chat.completions.create(\n",
    "        model=MODEL_GPT,\n",
    "        messages=conversation_history,\n",
    "        stream=True,\n",
    "    )\n",
    "    response = \"\"\n",
    "    \n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        \n",
    "        yield response\n",
    "    conversation_history.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9676679-34c0-44ce-8a1a-10dfbcc7ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = gr.Interface(\n",
    "    fn=chatGptResponse,\n",
    "    inputs=[gr.Textbox(label=\"Your message:\"),gr.File(label=\"Upload file\")],\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()\n",
    "#view.launch(server_name=\"10.75.32.62\", server_port=7866)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07048fdd-92d6-4e23-b56f-090767aa7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a8f11f-12b1-46e3-aa35-a1c5f18618ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
