{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731e55e-b710-42ed-8607-d867045a8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from week2_novel import *\n",
    "import nbimporter, importlib\n",
    "import utility_fncs, global_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9764c0-b9ff-4cdd-9f9e-74c4ed83d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "from typing import get_origin, get_args, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884a201-aea6-4732-b6e1-e132da62dd3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742017d2-270b-44dd-a963-d509320dd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool functions\n",
    "# Define function with type hints and a specific docstring format\n",
    "\n",
    "def get_current_weather(location: str, unit: Literal[\"celsius\", \"fahrenheit\"] = \"celsius\"):\n",
    "    \"\"\"Gets the current weather in a given location.\n",
    "    It can be a city, state format\n",
    "\n",
    "    Args:\n",
    "        location (str): The city and state, e.g., San Francisco, CA.\n",
    "        a example if of form San Francisco, CA\n",
    "        unit (str): The unit of temperature, either 'celsius' or 'fahrenheit'.\n",
    "    \"\"\"\n",
    "    # function logic     \n",
    "    return_dict={\n",
    "        'type':'json',\n",
    "        'content':'',\n",
    "    }\n",
    "    if \"san francisco\" in location.lower():\n",
    "        return_dict['content']=json.dumps({\"location\": location, \"temperature\": \"15\", \"unit\": unit})\n",
    "    elif \"tokyo\" in location.lower():\n",
    "        return_dict['content']= json.dumps({\"location\": location, \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return_dict['content']= json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str):\n",
    "    \"\"\"Retrieves the current stock price for a given ticker symbol.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): The stock ticker symbol, e.g., AAPL for Apple, GOOG for Google.\n",
    "    \"\"\"\n",
    "    return_dict={\n",
    "        'type':'json',\n",
    "        'content':'',\n",
    "    }\n",
    "    if symbol.upper() == \"AAPL\":\n",
    "        return_dict['content']= json.dumps({\"symbol\": \"AAPL\", \"price\": \"175.28\"})\n",
    "    else:\n",
    "        return_dict['content']= json.dumps({\"symbol\": symbol, \"price\": \"not found\"})\n",
    "    return return_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ecd4c-087d-4e20-9884-5a836984de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def create_image(msg: str):\n",
    "    \"\"\"\"Generates an image from a detailed text prompt. Use this tool when a user explicitly asks to draw or create a picture,\n",
    "    OR when a visual aid would significantly help in explaining a complex concept or answering a question.\"\n",
    "\n",
    "    Args:\n",
    "        msg(str) : the string that can be passed as a input to openai image generation (openai.image.generate) call's  keyword argument prompt. \n",
    "        It has to obtained from the user's message or intention requesting for a iamge\n",
    "    \"\"\"\n",
    "    return_dict={\n",
    "        'type':'image',\n",
    "        'content':'',\n",
    "    }\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=msg,\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    \n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return_dict['content']=Image.open(BytesIO(image_data))\n",
    "    print(return_dict['content'])\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f33353-b027-4290-a3a4-bc89a8d08ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai\n",
    "#create_image('create image of a sunrise in the Himalayas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bf742-8598-488a-9ddb-cc77d4c39ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "tool_fncs = []\n",
    "tool_fncs.append(utility_fncs.create_tool_from_function(get_current_weather))\n",
    "available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"get_stock_price\": get_stock_price,\n",
    "        \"create_image\": create_image,\n",
    "    }\n",
    "def chat_gpt_tool_call(qt, file=None, model=None):\n",
    "    #print(qt)\n",
    "    #msg = utility_fncs.create_gpt_prompt(qt,\"user\")\n",
    "    #print(msg)\n",
    "    #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt,msg)\n",
    "    #print(global_vars.prompt_gpt)\n",
    "    user_image = None\n",
    "    global_vars.prompt_gpt.append({\"role\": \"user\", \"content\":qt})\n",
    "    openai = OpenAI()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=global_vars.model_openai_4_5_preview,\n",
    "        messages=global_vars.prompt_gpt,        \n",
    "        tools=tool_fncs\n",
    "    )\n",
    "    #print(response)\n",
    "    reply = response.choices[0].message\n",
    "    reply_tool_calls = reply.tool_calls\n",
    "    if reply_tool_calls:\n",
    "        # list to hold the reply from tool calls\n",
    "        tool_messages = []\n",
    "        for reply_tool_call in reply_tool_calls:\n",
    "            function_name = reply_tool_call.function.name\n",
    "            function_to_call = available_functions.get(function_name,None)\n",
    "            if not function_to_call:\n",
    "                continue\n",
    "            function_args = json.loads(reply_tool_call.function.arguments)\n",
    "\n",
    "            # call our tool\n",
    "            function_response  = function_to_call(**function_args)\n",
    "            if (isinstance(function_response,dict)):\n",
    "                if function_response.get('type')=='image':\n",
    "                    user_image = function_response.get('content')\n",
    "                    function_response = \"Image created as per user's request\"\n",
    "                else:\n",
    "                    function_response=function_response.get('content','')\n",
    "            tool_messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\" : reply_tool_call.id,\n",
    "                    \"role\" : \"tool\",\n",
    "                    \"name\" : function_name,\n",
    "                    \"content\" : function_response,\n",
    "                }\n",
    "            )\n",
    "            global_vars.prompt_gpt.append(reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, *tool_messages)\n",
    "            global_vars.prompt_gpt.append(*tool_messages)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model_openai_4onano,\n",
    "                messages=global_vars.prompt_gpt,\n",
    "            )\n",
    "   # print(user_image)\n",
    "    return response.choices[0].message.content, user_image\n",
    "    \n",
    "                \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966a9de-2a97-4313-9377-21edcf3ac933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_vars.prompt_gpt = utility_fncs.reset_conv_history(global_vars.prompt_gpt,utility_fncs.create_gpt_prompt(global_vars.system_gpt_msg,'assistant'))\n",
    "#chat_gpt_tool_call('weather in tokyo?')\n",
    "#launcher = utility_fncs.get_gradio_launcher(chat_gpt_tool_call)\n",
    "tool_fncs.append(utility_fncs.create_tool_from_function(create_image))\n",
    "#global_vars.prompt_gpt = utility_fncs.reset_conv_history(global_vars.prompt_gpt,utility_fncs.create_gpt_prompt(global_vars.system_gpt_msg,'assistant'))\n",
    "#launcher = utility_fncs.get_gradio_multi_modal_launcher(chat_gpt_tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88664e-1c3c-4159-97b8-ff3cff507bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(history,qt):\n",
    "    messages = [{\"role\": \"system\", \"content\": global_vars.system_gpt_msg}] + history\n",
    "    \n",
    "    global_vars.prompt_gpt.append(history[-1])\n",
    "    response = openai.chat.completions.create(model=global_vars.model_openai_4_5_preview, messages=global_vars.prompt_gpt, tools=tool_fncs)\n",
    "    reply = response.choices[0].message\n",
    "    reply_tool_calls = reply.tool_calls\n",
    "    user_image = None\n",
    "    if reply_tool_calls:\n",
    "        # list to hold the reply from tool calls\n",
    "        tool_messages = []\n",
    "        for reply_tool_call in reply_tool_calls:\n",
    "            function_name = reply_tool_call.function.name\n",
    "            function_to_call = available_functions.get(function_name,None)\n",
    "            if not function_to_call:\n",
    "                continue\n",
    "            function_args = json.loads(reply_tool_call.function.arguments)\n",
    "\n",
    "            # call our tool\n",
    "            function_response  = function_to_call(**function_args)\n",
    "            if (isinstance(function_response,dict)):\n",
    "                if function_response.get('type')=='image':\n",
    "                    user_image = function_response.get('content')\n",
    "                    function_response = \"Image created as per user's request\"\n",
    "                else:\n",
    "                    function_response=function_response.get('content','')\n",
    "            tool_messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\" : reply_tool_call.id,\n",
    "                    \"role\" : \"tool\",\n",
    "                    \"name\" : function_name,\n",
    "                    \"content\" : function_response,\n",
    "                }\n",
    "            )\n",
    "            global_vars.prompt_gpt.append(reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, *tool_messages)\n",
    "            global_vars.prompt_gpt.append(*tool_messages)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=global_vars.model_openai_4_5_preview,\n",
    "                messages=global_vars.prompt_gpt,\n",
    "            )\n",
    "    global_vars.prompt_gpt.append({'role':'assistant', 'content':response.choices[0].message.content})\n",
    "    history = history + [{'role':'assistant', 'content':response.choices[0].message.content}]\n",
    "    print(history)\n",
    "    return history,user_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d45d1-8dd8-4aa1-b378-4b98a229ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vars.prompt_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1631e8c-cdf7-48c8-93d5-0dc0fd50c371",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher = utility_fncs.get_new_chat_interface(chat)\n",
    "launcher.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbb747-c1e4-4a29-94f9-d12154575de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"finish_reason\": \"tool_calls\",\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": null,\n",
    "        \"tool_calls\": [\n",
    "          {\n",
    "            \"id\": \"call_abc123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_current_weather\",\n",
    "              \"arguments\": \"{\\\"location\\\": \\\"San Francisco, CA\\\"}\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"id\": \"call_xyz789\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_stock_price\",\n",
    "              \"arguments\": \"{\\\"symbol\\\": \\\"AAPL\\\"}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  ...\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
