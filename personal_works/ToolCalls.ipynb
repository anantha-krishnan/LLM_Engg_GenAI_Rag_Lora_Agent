{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f731e55e-b710-42ed-8607-d867045a8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from week2_novel import *\n",
    "import nbimporter, importlib\n",
    "import utility_fncs, global_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f9764c0-b9ff-4cdd-9f9e-74c4ed83d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "from typing import get_origin, get_args, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d884a201-aea6-4732-b6e1-e132da62dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tool_from_function(func):\n",
    "    \"\"\"\n",
    "    Generates an OpenAI-compatible tool definition from a Python function.\n",
    "\n",
    "    This function leverages type hints and a structured docstring to create \n",
    "    the JSON schema required by the OpenAI API for tool-calling.\n",
    "\n",
    "    It supports multi-line function descriptions and multi-line parameter\n",
    "    descriptions.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to be converted into a tool.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the tool in the format expected by\n",
    "              the OpenAI API.\n",
    "    \"\"\"\n",
    "    # Get the clean, un-indented docstring\n",
    "    full_docstring = inspect.getdoc(func)\n",
    "    if not full_docstring:\n",
    "        raise ValueError(\"The function must have a docstring to be used as a tool.\")\n",
    "    \n",
    "    lines = [line.strip() for line in full_docstring.strip().split('\\n')]\n",
    "    \n",
    "    # --- 1. Parse Function and Parameter Descriptions ---\n",
    "    try:\n",
    "        args_section_index = lines.index('Args:')\n",
    "    except ValueError:\n",
    "        args_section_index = len(lines)\n",
    "\n",
    "    func_description = \"\\n\".join(lines[:args_section_index]).strip()\n",
    "    \n",
    "    # Robustly parse multi-line argument descriptions\n",
    "    param_docs = {}\n",
    "    current_param_name = None\n",
    "    args_section_lines = lines[args_section_index + 1:]\n",
    "\n",
    "    for line in args_section_lines:\n",
    "        if ':' in line:\n",
    "            param_name, param_desc = line.split(':', 1)\n",
    "            param_name = param_name.split('(')[0].strip()\n",
    "            # Start a new list of description lines for this parameter\n",
    "            param_docs[param_name] = [param_desc.strip()]\n",
    "            current_param_name = param_name\n",
    "        elif current_param_name:\n",
    "            # If a line doesn't have a colon, it's a continuation of the last parameter\n",
    "            param_docs[current_param_name].append(line.strip())\n",
    "\n",
    "    # Join the multi-line descriptions back into single strings\n",
    "    for name, desc_lines in param_docs.items():\n",
    "        param_docs[name] = \"\\n\".join(desc_lines)\n",
    "\n",
    "    # --- 2. Introspect Function Signature ---\n",
    "    sig = inspect.signature(func)\n",
    "    parameters_schema = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
    "    type_mapping = {str: \"string\", int: \"integer\", float: \"number\", bool: \"boolean\", dict: \"object\"}\n",
    "\n",
    "    for name, param in sig.parameters.items():\n",
    "        if param.default == inspect.Parameter.empty and name != 'self':\n",
    "            parameters_schema[\"required\"].append(name)\n",
    "\n",
    "        param_info = {}\n",
    "        if get_origin(param.annotation) is Literal:\n",
    "            param_info[\"type\"] = \"string\"\n",
    "            param_info[\"enum\"] = list(get_args(param.annotation))\n",
    "        else:\n",
    "            param_info[\"type\"] = type_mapping.get(param.annotation, \"string\")\n",
    "            \n",
    "        if name in param_docs:\n",
    "            param_info[\"description\"] = param_docs[name]\n",
    "\n",
    "        parameters_schema[\"properties\"][name] = param_info\n",
    "        \n",
    "    if not parameters_schema[\"properties\"]:\n",
    "        parameters_schema = {\"type\": \"object\", \"properties\": {}}\n",
    "\n",
    "    # --- 3. Assemble Final Tool ---\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": func_description,\n",
    "            \"parameters\": parameters_schema,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742017d2-270b-44dd-a963-d509320dd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool functions\n",
    "# Define function with type hints and a specific docstring format\n",
    "\n",
    "def get_current_weather(location: str, unit: Literal[\"celsius\", \"fahrenheit\"] = \"celsius\"):\n",
    "    \"\"\"Gets the current weather in a given location.\n",
    "    It can be a city, state format\n",
    "\n",
    "    Args:\n",
    "        location (str): The city and state, e.g., San Francisco, CA.\n",
    "        a example if of form San Francisco, CA\n",
    "        unit (str): The unit of temperature, either 'celsius' or 'fahrenheit'.\n",
    "    \"\"\"\n",
    "    # function logic     \n",
    "    return_dict={\n",
    "        'type':'json',\n",
    "        'content':'',\n",
    "    }\n",
    "    if \"san francisco\" in location.lower():\n",
    "        return_dict['content']=json.dumps({\"location\": location, \"temperature\": \"15\", \"unit\": unit})\n",
    "    elif \"tokyo\" in location.lower():\n",
    "        return_dict['content']= json.dumps({\"location\": location, \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return_dict['content']= json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "    return return_dict\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str):\n",
    "    \"\"\"Retrieves the current stock price for a given ticker symbol.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): The stock ticker symbol, e.g., AAPL for Apple, GOOG for Google.\n",
    "    \"\"\"\n",
    "    return_dict={\n",
    "        'type':'json',\n",
    "        'content':'',\n",
    "    }\n",
    "    if symbol.upper() == \"AAPL\":\n",
    "        return_dict['content']= json.dumps({\"symbol\": \"AAPL\", \"price\": \"175.28\"})\n",
    "    else:\n",
    "        return_dict['content']= json.dumps({\"symbol\": symbol, \"price\": \"not found\"})\n",
    "    return return_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42ecd4c-087d-4e20-9884-5a836984de82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "\n",
    "def create_image(msg: str):\n",
    "    \"\"\"\"Generates an image from a detailed text prompt. Use this tool when a user explicitly asks to draw or create a picture,\n",
    "    OR when a visual aid would significantly help in explaining a complex concept or answering a question.\"\n",
    "\n",
    "    Args:\n",
    "        msg(str) : the string that can be passed as a input to openai image generation (openai.image.generate) call's  keyword argument prompt. \n",
    "        It has to obtained from the user's message or intention requesting for a iamge\n",
    "    \"\"\"\n",
    "    return_dict={\n",
    "        'type':'image',\n",
    "        'content':'',\n",
    "    }\n",
    "    image_response = openai.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt=msg,\n",
    "            size=\"1024x1024\",\n",
    "            n=1,\n",
    "            response_format=\"b64_json\",\n",
    "        )\n",
    "    \n",
    "    image_base64 = image_response.data[0].b64_json\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    return_dict['content']=Image.open(BytesIO(image_data))\n",
    "    print(return_dict['content'])\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4f33353-b027-4290-a3a4-bc89a8d08ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai\n",
    "#create_image('create image of a sunrise in the Himalayas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7bf742-8598-488a-9ddb-cc77d4c39ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "tool_fncs = []\n",
    "tool_fncs.append(create_tool_from_function(get_current_weather))\n",
    "available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"get_stock_price\": get_stock_price,\n",
    "        \"create_image\": create_image,\n",
    "    }\n",
    "def chat_gpt_tool_call(qt, file=None, model=None):\n",
    "    #print(qt)\n",
    "    #msg = utility_fncs.create_gpt_prompt(qt,\"user\")\n",
    "    #print(msg)\n",
    "    #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt,msg)\n",
    "    #print(global_vars.prompt_gpt)\n",
    "    user_image = None\n",
    "    global_vars.prompt_gpt.append({\"role\": \"user\", \"content\":qt})\n",
    "    openai = OpenAI()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=global_vars.model_openai_4_5_preview,\n",
    "        messages=global_vars.prompt_gpt,        \n",
    "        tools=tool_fncs\n",
    "    )\n",
    "    #print(response)\n",
    "    reply = response.choices[0].message\n",
    "    reply_tool_calls = reply.tool_calls\n",
    "    if reply_tool_calls:\n",
    "        # list to hold the reply from tool calls\n",
    "        tool_messages = []\n",
    "        for reply_tool_call in reply_tool_calls:\n",
    "            function_name = reply_tool_call.function.name\n",
    "            function_to_call = available_functions.get(function_name,None)\n",
    "            if not function_to_call:\n",
    "                continue\n",
    "            function_args = json.loads(reply_tool_call.function.arguments)\n",
    "\n",
    "            # call our tool\n",
    "            function_response  = function_to_call(**function_args)\n",
    "            if (isinstance(function_response,dict)):\n",
    "                if function_response.get('type')=='image':\n",
    "                    user_image = function_response.get('content')\n",
    "                    function_response = \"Image created as per user's request\"\n",
    "                else:\n",
    "                    function_response=function_response.get('content','')\n",
    "            tool_messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\" : reply_tool_call.id,\n",
    "                    \"role\" : \"tool\",\n",
    "                    \"name\" : function_name,\n",
    "                    \"content\" : function_response,\n",
    "                }\n",
    "            )\n",
    "            global_vars.prompt_gpt.append(reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, *tool_messages)\n",
    "            global_vars.prompt_gpt.append(*tool_messages)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model_openai_4onano,\n",
    "                messages=global_vars.prompt_gpt,\n",
    "            )\n",
    "    print(user_image)\n",
    "    return response.choices[0].message.content, user_image\n",
    "    \n",
    "                \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d966a9de-2a97-4313-9377-21edcf3ac933",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global_vars.prompt_gpt = utility_fncs.reset_conv_history(global_vars.prompt_gpt,utility_fncs.create_gpt_prompt(global_vars.system_gpt_msg,'assistant'))\n",
    "#chat_gpt_tool_call('weather in tokyo?')\n",
    "#launcher = utility_fncs.get_gradio_launcher(chat_gpt_tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be88664e-1c3c-4159-97b8-ff3cff507bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "367d45d1-8dd8-4aa1-b378-4b98a229ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_fncs.append(create_tool_from_function(create_image))\n",
    "global_vars.prompt_gpt = utility_fncs.reset_conv_history(global_vars.prompt_gpt,utility_fncs.create_gpt_prompt(global_vars.system_gpt_msg,'assistant'))\n",
    "launcher = utility_fncs.get_gradio_multi_modal_launcher(chat_gpt_tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1631e8c-cdf7-48c8-93d5-0dc0fd50c371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "launcher.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5dbb747-c1e4-4a29-94f9-d12154575de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n  \"choices\": [\\n    {\\n      \"finish_reason\": \"tool_calls\",\\n      \"index\": 0,\\n      \"message\": {\\n        \"role\": \"assistant\",\\n        \"content\": null,\\n        \"tool_calls\": [\\n          {\\n            \"id\": \"call_abc123\",\\n            \"type\": \"function\",\\n            \"function\": {\\n              \"name\": \"get_current_weather\",\\n              \"arguments\": \"{\"location\": \"San Francisco, CA\"}\"\\n            }\\n          },\\n          {\\n            \"id\": \"call_xyz789\",\\n            \"type\": \"function\",\\n            \"function\": {\\n              \"name\": \"get_stock_price\",\\n              \"arguments\": \"{\"symbol\": \"AAPL\"}\"\\n            }\\n          }\\n        ]\\n      }\\n    }\\n  ],\\n  ...\\n}\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"finish_reason\": \"tool_calls\",\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": null,\n",
    "        \"tool_calls\": [\n",
    "          {\n",
    "            \"id\": \"call_abc123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_current_weather\",\n",
    "              \"arguments\": \"{\\\"location\\\": \\\"San Francisco, CA\\\"}\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"id\": \"call_xyz789\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_stock_price\",\n",
    "              \"arguments\": \"{\\\"symbol\\\": \\\"AAPL\\\"}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  ...\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
