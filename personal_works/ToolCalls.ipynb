{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f731e55e-b710-42ed-8607-d867045a8a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from week2_novel import *\n",
    "import nbimporter, importlib\n",
    "import utility_fncs, global_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9764c0-b9ff-4cdd-9f9e-74c4ed83d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "from typing import get_origin, get_args, Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884a201-aea6-4732-b6e1-e132da62dd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tool_from_function(func):\n",
    "    \"\"\"\n",
    "    Generates an OpenAI-compatible tool definition from a Python function.\n",
    "\n",
    "    This function leverages type hints and a structured docstring to create \n",
    "    the JSON schema required by the OpenAI API for tool-calling.\n",
    "\n",
    "    It supports multi-line function descriptions and multi-line parameter\n",
    "    descriptions.\n",
    "\n",
    "    Args:\n",
    "        func (callable): The function to be converted into a tool.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary representing the tool in the format expected by\n",
    "              the OpenAI API.\n",
    "    \"\"\"\n",
    "    # Get the clean, un-indented docstring\n",
    "    full_docstring = inspect.getdoc(func)\n",
    "    if not full_docstring:\n",
    "        raise ValueError(\"The function must have a docstring to be used as a tool.\")\n",
    "    \n",
    "    lines = [line.strip() for line in full_docstring.strip().split('\\n')]\n",
    "    \n",
    "    # --- 1. Parse Function and Parameter Descriptions ---\n",
    "    try:\n",
    "        args_section_index = lines.index('Args:')\n",
    "    except ValueError:\n",
    "        args_section_index = len(lines)\n",
    "\n",
    "    func_description = \"\\n\".join(lines[:args_section_index]).strip()\n",
    "    \n",
    "    # Robustly parse multi-line argument descriptions\n",
    "    param_docs = {}\n",
    "    current_param_name = None\n",
    "    args_section_lines = lines[args_section_index + 1:]\n",
    "\n",
    "    for line in args_section_lines:\n",
    "        if ':' in line:\n",
    "            param_name, param_desc = line.split(':', 1)\n",
    "            param_name = param_name.split('(')[0].strip()\n",
    "            # Start a new list of description lines for this parameter\n",
    "            param_docs[param_name] = [param_desc.strip()]\n",
    "            current_param_name = param_name\n",
    "        elif current_param_name:\n",
    "            # If a line doesn't have a colon, it's a continuation of the last parameter\n",
    "            param_docs[current_param_name].append(line.strip())\n",
    "\n",
    "    # Join the multi-line descriptions back into single strings\n",
    "    for name, desc_lines in param_docs.items():\n",
    "        param_docs[name] = \"\\n\".join(desc_lines)\n",
    "\n",
    "    # --- 2. Introspect Function Signature ---\n",
    "    sig = inspect.signature(func)\n",
    "    parameters_schema = {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
    "    type_mapping = {str: \"string\", int: \"integer\", float: \"number\", bool: \"boolean\", dict: \"object\"}\n",
    "\n",
    "    for name, param in sig.parameters.items():\n",
    "        if param.default == inspect.Parameter.empty and name != 'self':\n",
    "            parameters_schema[\"required\"].append(name)\n",
    "\n",
    "        param_info = {}\n",
    "        if get_origin(param.annotation) is Literal:\n",
    "            param_info[\"type\"] = \"string\"\n",
    "            param_info[\"enum\"] = list(get_args(param.annotation))\n",
    "        else:\n",
    "            param_info[\"type\"] = type_mapping.get(param.annotation, \"string\")\n",
    "            \n",
    "        if name in param_docs:\n",
    "            param_info[\"description\"] = param_docs[name]\n",
    "\n",
    "        parameters_schema[\"properties\"][name] = param_info\n",
    "        \n",
    "    if not parameters_schema[\"properties\"]:\n",
    "        parameters_schema = {\"type\": \"object\", \"properties\": {}}\n",
    "\n",
    "    # --- 3. Assemble Final Tool ---\n",
    "    return {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": func.__name__,\n",
    "            \"description\": func_description,\n",
    "            \"parameters\": parameters_schema,\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742017d2-270b-44dd-a963-d509320dd456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tool functions\n",
    "# Define function with type hints and a specific docstring format\n",
    "\n",
    "def get_current_weather(location: str, unit: Literal[\"celsius\", \"fahrenheit\"] = \"celsius\"):\n",
    "    \"\"\"Gets the current weather in a given location.\n",
    "    It can be a city, state format\n",
    "\n",
    "    Args:\n",
    "        location (str): The city and state, e.g., San Francisco, CA.\n",
    "        a example if of form San Francisco, CA\n",
    "        unit (str): The unit of temperature, either 'celsius' or 'fahrenheit'.\n",
    "    \"\"\"\n",
    "    # function logic     \n",
    "    if \"san francisco\" in location.lower():\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"15\", \"unit\": unit})\n",
    "    elif \"tokyo\" in location.lower():\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"22\", \"unit\": unit})\n",
    "    else:\n",
    "        return json.dumps({\"location\": location, \"temperature\": \"unknown\"})\n",
    "\n",
    "\n",
    "def get_stock_price(symbol: str):\n",
    "    \"\"\"Retrieves the current stock price for a given ticker symbol.\n",
    "    \n",
    "    Args:\n",
    "        symbol (str): The stock ticker symbol, e.g., AAPL for Apple, GOOG for Google.\n",
    "    \"\"\"\n",
    "    \n",
    "    if symbol.upper() == \"AAPL\":\n",
    "        return json.dumps({\"symbol\": \"AAPL\", \"price\": \"175.28\"})\n",
    "    else:\n",
    "        return json.dumps({\"symbol\": symbol, \"price\": \"not found\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7bf742-8598-488a-9ddb-cc77d4c39ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "tool_fncs = []\n",
    "tool_fncs.append(create_tool_from_function(get_current_weather))\n",
    "available_functions = {\n",
    "        \"get_current_weather\": get_current_weather,\n",
    "        \"get_stock_price\": get_stock_price,\n",
    "    }\n",
    "def chat_gpt_tool_call(qt, file=None, model=None):\n",
    "    #print(qt)\n",
    "    #msg = utility_fncs.create_gpt_prompt(qt,\"user\")\n",
    "    #print(msg)\n",
    "    #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt,msg)\n",
    "    #print(global_vars.prompt_gpt)\n",
    "    global_vars.prompt_gpt.append({\"role\": \"user\", \"content\":qt})\n",
    "    openai = OpenAI()\n",
    "    response = openai.chat.completions.create(\n",
    "        model=global_vars.model_openai_4onano,\n",
    "        messages=global_vars.prompt_gpt,        \n",
    "        tools=tool_fncs\n",
    "    )\n",
    "    #print(response)\n",
    "    reply = response.choices[0].message\n",
    "    reply_tool_calls = reply.tool_calls\n",
    "    if reply_tool_calls:\n",
    "        # list to hold the reply from tool calls\n",
    "        tool_messages = []\n",
    "        for reply_tool_call in reply_tool_calls:\n",
    "            function_name = reply_tool_call.function.name\n",
    "            function_to_call = available_functions.get(function_name,None)\n",
    "            if not function_to_call:\n",
    "                continue\n",
    "            function_args = json.loads(reply_tool_call.function.arguments)\n",
    "\n",
    "            # call our tool\n",
    "            function_response  = function_to_call(**function_args)\n",
    "            tool_messages.append(\n",
    "                {\n",
    "                    \"tool_call_id\" : reply_tool_call.id,\n",
    "                    \"role\" : \"tool\",\n",
    "                    \"name\" : function_name,\n",
    "                    \"content\" : function_response,\n",
    "                }\n",
    "            )\n",
    "            global_vars.prompt_gpt.append(reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, reply)\n",
    "            #global_vars.prompt_gpt = utility_fncs.append_conv(global_vars.prompt_gpt, *tool_messages)\n",
    "            global_vars.prompt_gpt.append(*tool_messages)\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model_openai_4onano,\n",
    "                messages=global_vars.prompt_gpt,\n",
    "                stream=True\n",
    "            )\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "                \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d966a9de-2a97-4313-9377-21edcf3ac933",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_vars.prompt_gpt = utility_fncs.reset_conv_history(global_vars.prompt_gpt,utility_fncs.create_gpt_prompt(global_vars.system_gpt_msg,'assistant'))\n",
    "#chat_gpt_tool_call('weather in tokyo?')\n",
    "launcher = utility_fncs.get_gradio_launcher(chat_gpt_tool_call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d45d1-8dd8-4aa1-b378-4b98a229ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "launcher.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dbb747-c1e4-4a29-94f9-d12154575de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "{\n",
    "  \"choices\": [\n",
    "    {\n",
    "      \"finish_reason\": \"tool_calls\",\n",
    "      \"index\": 0,\n",
    "      \"message\": {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": null,\n",
    "        \"tool_calls\": [\n",
    "          {\n",
    "            \"id\": \"call_abc123\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_current_weather\",\n",
    "              \"arguments\": \"{\\\"location\\\": \\\"San Francisco, CA\\\"}\"\n",
    "            }\n",
    "          },\n",
    "          {\n",
    "            \"id\": \"call_xyz789\",\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"get_stock_price\",\n",
    "              \"arguments\": \"{\\\"symbol\\\": \\\"AAPL\\\"}\"\n",
    "            }\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  ...\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
